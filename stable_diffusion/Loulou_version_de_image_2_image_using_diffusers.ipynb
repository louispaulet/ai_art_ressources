{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "toc_visible": true,
      "private_outputs": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Image2Image Pipeline for Stable Diffusion using ðŸ§¨ Diffusers \n",
        "\n",
        "This notebook shows how to create a custom `diffusers` pipeline for  text-guided image-to-image generation with Stable Diffusion model using  ðŸ¤— Hugging Face [ðŸ§¨ Diffusers library](https://github.com/huggingface/diffusers). \n",
        "\n",
        "For a general introduction to the Stable Diffusion model please refer to this [colab](https://colab.research.google.com/github/huggingface/notebooks/blob/main/diffusers/stable_diffusion.ipynb).\n",
        "\n"
      ],
      "metadata": {
        "id": "846pN2uHGJLx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "z4wiAYmxAGlK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L52bmJXkAMQz"
      },
      "outputs": [],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install diffusers==0.3.0 transformers ftfy\n",
        "!pip install -qq \"ipywidgets>=7,<8\""
      ],
      "metadata": {
        "id": "n9AmMcAGASDq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "You need to accept the model license before downloading or using the weights. In this post we'll use model version `v1-4`, so you'll need to  visit [its card](https://huggingface.co/CompVis/stable-diffusion-v1-4), read the license and tick the checkbox if you agree. \n",
        "\n",
        "You have to be a registered user in ðŸ¤— Hugging Face Hub, and you'll also need to use an access token for the code to work. For more information on access tokens, please refer to [this section of the documentation](https://huggingface.co/docs/hub/security-tokens)."
      ],
      "metadata": {
        "id": "DQ11k9JVIXII"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from huggingface_hub import notebook_login\n",
        "\n",
        "notebook_login()"
      ],
      "metadata": {
        "id": "AOe3MmjoAoSU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Image2Image pipeline."
      ],
      "metadata": {
        "id": "Uclfq60nIQvm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import inspect\n",
        "import warnings\n",
        "from typing import List, Optional, Union\n",
        "\n",
        "import torch\n",
        "from torch import autocast\n",
        "from tqdm.auto import tqdm\n",
        "\n",
        "from diffusers import StableDiffusionImg2ImgPipeline"
      ],
      "metadata": {
        "id": "2YJrHBHlB54B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load the pipeline"
      ],
      "metadata": {
        "id": "YL179UtGKweb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "device = \"cuda\"\n",
        "model_path = \"CompVis/stable-diffusion-v1-4\"\n",
        "\n",
        "pipe = StableDiffusionImg2ImgPipeline.from_pretrained(\n",
        "    model_path,\n",
        "    revision=\"fp16\", \n",
        "    torch_dtype=torch.float16,\n",
        "    use_auth_token=True\n",
        ")\n",
        "pipe = pipe.to(device)"
      ],
      "metadata": {
        "id": "Fr2QIEzvCFH2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Download an initial image and preprocess it so we can pass it to the pipeline."
      ],
      "metadata": {
        "id": "tFBvRqfCKzVQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "from io import BytesIO\n",
        "from PIL import Image\n",
        "from datetime import datetime\n",
        "\n",
        "# init_image_path = '/content/drive/MyDrive/AI/IMG2IMG_stable_diffusion/init_image/image.png'\n",
        "\n",
        "# init_image_path = '/content/drive/MyDrive/AI/IMG2IMG_stable_diffusion/init_image/base_frame.png'\n",
        "init_image_path = '/content/drive/MyDrive/AI/IMG2IMG_stable_diffusion/init_image/large_blue_vase.png'\n",
        "\n",
        "# init_image_path = '/content/drive/MyDrive/AI/IMG2IMG_stable_diffusion/init_image/5 large blue and white vases.png'\n",
        "init_img = Image.open(init_image_path).convert(\"RGB\")\n",
        "init_img = init_img.resize((512, 768))\n",
        "init_img"
      ],
      "metadata": {
        "id": "4dacsTgWBwb3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### black and white option\n",
        "# init_img = init_img.convert('L')\n",
        "# init_img = init_img.convert('RGB')\n",
        "# init_img"
      ],
      "metadata": {
        "id": "GJZZC-mHbG23"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Define the prompt and run the pipeline."
      ],
      "metadata": {
        "id": "XgtE5Qn9LE1m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = \"A large blue and white baluster vase and cover, Qing dynasty, Kangxi period 1722, in the style of Van Gogh, the starry night motif\""
      ],
      "metadata": {
        "id": "8ypdl7SrEzdh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt =\"VASE EN PORCELAINE BLEU BLANC, Chine, dynastie Qing, fin du XVIIIe siÃ¨cle. De forme de balustre, Ã  dÃ©cor de fleurs et rinceaux feuillagÃ©s, la bordure du col ornÃ©e d'une frise feuilles, le pied, de flots stylisÃ©s\""
      ],
      "metadata": {
        "id": "z9Vx2UDbJfVP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt = \"A magnificent and very rare carved green-glazed vase with intricate and very detailed flowers carvings, delicately enamelled, Christies auction, high quality picture of a vase in a white background\""
      ],
      "metadata": {
        "id": "LF1Ktl2o7qRL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt = \"a pair of french armchairs in the style Louis XV ormolu, bright colorful floral pattern on the armchair textiles, gilded wooden armchairs, high resolution award winning photograph\""
      ],
      "metadata": {
        "id": "4V11Z0l-ZUWJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here, `strength` is a value between 0.0 and 1.0, that controls the amount of noise that is added to the input image. Values that approach 1.0 allow for lots of variations but will also produce images that are not semantically consistent with the input."
      ],
      "metadata": {
        "id": "8wOmwKnkDfpd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def produce_one_image_per_seed(seed):\n",
        "  generator = torch.Generator(device=device).manual_seed(seed)\n",
        "\n",
        "  now = datetime.now() \n",
        "  time = now.strftime(\"%H%M%S\")\n",
        "\n",
        "  with autocast(\"cuda\"):\n",
        "      pipe.safety_checker = (lambda images, clip_input: (images, False))\n",
        "      image = pipe(prompt=prompt, init_image=init_img, strength=0.65, guidance_scale=7.5, generator=generator).images[0]\n",
        "  image.save('/content/drive/MyDrive/AI/IMG2IMG_stable_diffusion/output/'+time+'image.png')\n",
        "  # display(image)"
      ],
      "metadata": {
        "id": "4P854XxEyD-2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def produce_one_image(input_strength):\n",
        "  generator = torch.Generator(device=device).manual_seed(4242)\n",
        "\n",
        "  now = datetime.now() \n",
        "  time = now.strftime(\"%H%M%S\")\n",
        "\n",
        "  with autocast(\"cuda\"):\n",
        "      pipe.safety_checker = (lambda images, clip_input: (images, False))\n",
        "      image = pipe(prompt=prompt, init_image=init_img, strength=input_strength, guidance_scale=7.5, generator=generator).images[0]\n",
        "  image.save('/content/drive/MyDrive/AI/IMG2IMG_stable_diffusion/output/'+time+'image.png')\n",
        "  # display(image)"
      ],
      "metadata": {
        "id": "gvpQ9D6jFqjD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# for input_strength in range(30, 90, 5):\n",
        "#   curr_coef = input_strength/100\n",
        "#   print(\"Computing coef: \"+str(curr_coef))\n",
        "#   produce_one_image(curr_coef)"
      ],
      "metadata": {
        "id": "BNtv89_-Ruta"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for input_strength in range(1, 200, 1):\n",
        "  curr_coef = input_strength*13\n",
        "  print(\"Computing coef: \"+str(curr_coef))\n",
        "  produce_one_image_per_seed(curr_coef)"
      ],
      "metadata": {
        "id": "OC2_s5uFFw2e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# for input_strength in range(1, 20, 1):\n",
        "#   curr_coef = input_strength*420\n",
        "#   print(\"Computing coef: \"+str(curr_coef))\n",
        "#   produce_one_image_per_seed(curr_coef)"
      ],
      "metadata": {
        "id": "aRLaDchyNWbS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir /content/drive/MyDrive/AI/IMG2IMG_stable_diffusion/$(date +%Y%m%d_%H%M%S) && mv /content/drive/MyDrive/AI/IMG2IMG_stable_diffusion/output/*.png /content/drive/MyDrive/AI/IMG2IMG_stable_diffusion/$(date +%Y%m%d_%H%M%S)"
      ],
      "metadata": {
        "id": "xo5TsZxekuhs"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}