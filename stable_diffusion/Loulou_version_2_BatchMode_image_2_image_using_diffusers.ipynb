{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "toc_visible": true,
      "private_outputs": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Image2Image Pipeline for Stable Diffusion using ðŸ§¨ Diffusers \n",
        "\n",
        "This notebook shows how to create a custom `diffusers` pipeline for  text-guided image-to-image generation with Stable Diffusion model using  ðŸ¤— Hugging Face [ðŸ§¨ Diffusers library](https://github.com/huggingface/diffusers). \n",
        "\n",
        "For a general introduction to the Stable Diffusion model please refer to this [colab](https://colab.research.google.com/github/huggingface/notebooks/blob/main/diffusers/stable_diffusion.ipynb).\n",
        "\n"
      ],
      "metadata": {
        "id": "846pN2uHGJLx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Setup"
      ],
      "metadata": {
        "id": "Mkgaont0VGRw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## import GDrive"
      ],
      "metadata": {
        "id": "uLWeucAKVIWw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "z4wiAYmxAGlK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Check GPU"
      ],
      "metadata": {
        "id": "bbFGTbibVKFO"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L52bmJXkAMQz"
      },
      "outputs": [],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Install libs"
      ],
      "metadata": {
        "id": "N8Ay8eRwVL38"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install diffusers==0.3.0 transformers ftfy\n",
        "!pip install -qq \"ipywidgets>=7,<8\""
      ],
      "metadata": {
        "id": "n9AmMcAGASDq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "You need to accept the model license before downloading or using the weights. In this post we'll use model version `v1-4`, so you'll need to  visit [its card](https://huggingface.co/CompVis/stable-diffusion-v1-4), read the license and tick the checkbox if you agree. \n",
        "\n",
        "You have to be a registered user in ðŸ¤— Hugging Face Hub, and you'll also need to use an access token for the code to work. For more information on access tokens, please refer to [this section of the documentation](https://huggingface.co/docs/hub/security-tokens)."
      ],
      "metadata": {
        "id": "DQ11k9JVIXII"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Token Login"
      ],
      "metadata": {
        "id": "mLPcwZdcVNt6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from huggingface_hub import notebook_login\n",
        "import inspect\n",
        "import warnings\n",
        "from typing import List, Optional, Union\n",
        "import torch\n",
        "from torch import autocast\n",
        "from tqdm.auto import tqdm\n",
        "import requests\n",
        "from io import BytesIO\n",
        "from PIL import Image\n",
        "from datetime import datetime\n",
        "from diffusers import StableDiffusionImg2ImgPipeline\n",
        "\n",
        "notebook_login()"
      ],
      "metadata": {
        "id": "AOe3MmjoAoSU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Image2Image pipeline."
      ],
      "metadata": {
        "id": "Uclfq60nIQvm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load the pipeline"
      ],
      "metadata": {
        "id": "YL179UtGKweb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "device = \"cuda\"\n",
        "model_path = \"CompVis/stable-diffusion-v1-4\"\n",
        "\n",
        "pipe = StableDiffusionImg2ImgPipeline.from_pretrained(\n",
        "    model_path,\n",
        "    revision=\"fp16\", \n",
        "    torch_dtype=torch.float16,\n",
        "    use_auth_token=True\n",
        ")\n",
        "pipe = pipe.to(device)"
      ],
      "metadata": {
        "id": "Fr2QIEzvCFH2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Download an initial image and preprocess it so we can pass it to the pipeline."
      ],
      "metadata": {
        "id": "tFBvRqfCKzVQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "batch_init_path = \"/content/drive/MyDrive/AI/IMG2IMG_stable_diffusion/init_image/batch_mode/\""
      ],
      "metadata": {
        "id": "wRv-DeDOWgFa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def produce_one_image_by_params(seed, init_image_path, prompt, s_ratio):\n",
        "  \n",
        "  init_img = Image.open(init_image_path).convert(\"RGB\")\n",
        "  init_img = init_img.resize((512, 512))\n",
        "\n",
        "  ### black and white option\n",
        "  # init_img = init_img.convert('L')\n",
        "  # init_img = init_img.convert('RGB')\n",
        "\n",
        "  generator = torch.Generator(device=device).manual_seed(seed)\n",
        "\n",
        "  now = datetime.now() \n",
        "  time = now.strftime(\"%H%M%S\")\n",
        "\n",
        "  with autocast(\"cuda\"):\n",
        "      pipe.safety_checker = (lambda images, clip_input: (images, False))\n",
        "      image = pipe(prompt=prompt, init_image=init_img, strength=s_ratio, guidance_scale=7.5, generator=generator).images[0]\n",
        "  image.save('/content/drive/MyDrive/AI/IMG2IMG_stable_diffusion/output/'+time+'image.png')\n",
        "  display(image)"
      ],
      "metadata": {
        "id": "QihwI76FWar_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = \"oil on canvas portrait of a 20 year old bearded man in the style of Grant Wood, trending on Artstation\""
      ],
      "metadata": {
        "id": "cxqvfp3Bmvfy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from glob import glob\n",
        "\n",
        "\n",
        "extension = 'png'\n",
        "# extension = 'jpg'\n",
        "input_file_paths = glob(batch_init_path+\"*/*.\"+extension, recursive = True)\n",
        "\n",
        "# for seed in range(0, 100, 1):\n",
        "seed = 42\n",
        "for file_path in input_file_paths:\n",
        "  for s_ratio in range(30, 80, 5):\n",
        "    for curr_seed in range(1, 4, 1):\n",
        "      produce_one_image_by_params(curr_seed*42, file_path, prompt, s_ratio/100)"
      ],
      "metadata": {
        "id": "nGPyaQsQWRZZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir /content/drive/MyDrive/AI/IMG2IMG_stable_diffusion/$(date +%Y%m%d_%H%M%S) && mv /content/drive/MyDrive/AI/IMG2IMG_stable_diffusion/output/*.png /content/drive/MyDrive/AI/IMG2IMG_stable_diffusion/$(date +%Y%m%d_%H%M%S)"
      ],
      "metadata": {
        "id": "xo5TsZxekuhs"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}