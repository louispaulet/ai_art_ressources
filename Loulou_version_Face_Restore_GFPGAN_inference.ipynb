{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "RJtKN6ANUADM"
      ],
      "private_outputs": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# GPU Check"
      ],
      "metadata": {
        "id": "1u0XeyIDrxTB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "metadata": {
        "id": "nYtr7tSoqUqP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RJtKN6ANUADM"
      },
      "source": [
        "# GFPGAN Inference Demo \n",
        "### (No colorization; No CUDA extensions required)\n",
        "\n",
        "[![arXiv](https://img.shields.io/badge/arXiv-Paper-<COLOR>.svg)](https://arxiv.org/abs/2101.04061)\n",
        "[![GitHub Stars](https://img.shields.io/github/stars/TencentARC/GFPGAN?style=social)](https://github.com/TencentARC/GFPGAN)\n",
        "[![download](https://img.shields.io/github/downloads/TencentARC/GFPGAN/total.svg)](https://github.com/TencentARC/GFPGAN/releases)\n",
        "\n",
        "## GFPGAN - Towards Real-World Blind Face Restoration with Generative Facial Prior\n",
        "\n",
        "GFPGAN is a blind face restoration algorithm towards real-world face images. <br>\n",
        "It leverages the generative face prior in a pre-trained GAN (*e.g.*, StyleGAN2) to restore realistic faces while precerving fidelity. <br>\n",
        "\n",
        "If you want to use the paper model, please go to this [Colab Demo](https://colab.research.google.com/drive/1Oa1WwKB4M4l1GmR7CtswDVgOCOeSLChA?usp=sharing) for GFPGAN <a href=\"https://colab.research.google.com/drive/1Oa1WwKB4M4l1GmR7CtswDVgOCOeSLChA?usp=sharing\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"google colab logo\"></a>.\n",
        "\n",
        "**Limitations**: GFPGAN could not handle all the low-quality faces in the real world. Therefore, it may fail on your own cases.\n",
        "\n",
        "###Enjoy! :-)\n",
        "\n",
        "<img src=\"https://xinntao.github.io/projects/GFPGAN_src/gfpgan_teaser.jpg\" width=\"800\">\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZY1Zbo3uUkXg"
      },
      "source": [
        "# 1. Preparations\n",
        "Before start, make sure that you choose\n",
        "* Runtime Type = Python 3\n",
        "* Hardware Accelerator = GPU\n",
        "\n",
        "in the **Runtime** menu -> **Change runtime type**\n",
        "\n",
        "Then, we clone the repository, set up the envrironment, and download the pre-trained model.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Mount GDrive"
      ],
      "metadata": {
        "id": "D7x2uz2ioC2k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "gu2Ar0Z5ncuZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Git clone repo"
      ],
      "metadata": {
        "id": "JOcoxsHaoJeK"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZwH2ifWEYEfJ"
      },
      "source": [
        "# Clone GFPGAN and enter the GFPGAN folder\n",
        "%cd /content\n",
        "!rm -rf GFPGAN\n",
        "!git clone https://github.com/TencentARC/GFPGAN.git\n",
        "%cd GFPGAN\n",
        "\n",
        "# Set up the environment\n",
        "# Install basicsr - https://github.com/xinntao/BasicSR\n",
        "# We use BasicSR for both training and inference\n",
        "!pip install basicsr\n",
        "# Install facexlib - https://github.com/xinntao/facexlib\n",
        "# We use face detection and face restoration helper in the facexlib package\n",
        "!pip install facexlib\n",
        "# Install other depencencies\n",
        "!pip install -r requirements.txt\n",
        "!python setup.py develop\n",
        "!pip install realesrgan  # used for enhancing the background (non-face) regions\n",
        "# Download the pre-trained model\n",
        "# !wget https://github.com/TencentARC/GFPGAN/releases/download/v0.2.0/GFPGANCleanv1-NoCE-C2.pth -P experiments/pretrained_models\n",
        "# Now we use the V1.3 model for the demo\n",
        "!wget https://github.com/TencentARC/GFPGAN/releases/download/v1.3.0/GFPGANv1.3.pth -P experiments/pretrained_models\n",
        "!apt install detox\n",
        "!pip install Pillow\n",
        "\n",
        "import shutil\n",
        "import os\n",
        "upload_folder = 'inputs/upload'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U-8JxpPwg4Xz"
      },
      "source": [
        "# 2. Upload Images / Use the demo images"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## OPTION: Clean and move files to upload folder"
      ],
      "metadata": {
        "id": "0DY-9W2JoF2x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!rm /content/GFPGAN/inputs/upload/*"
      ],
      "metadata": {
        "id": "sBNkmhfCeqXy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir /content/GFPGAN/inputs/upload"
      ],
      "metadata": {
        "id": "N6djKbKHnsli"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!cp -v /content/drive/MyDrive/AI/stable_diffusion/to_upscale/asian_female_polaroid_aging/* /content/GFPGAN/inputs/upload/"
      ],
      "metadata": {
        "id": "lcSy2-IgncV-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## sanitize input filenames"
      ],
      "metadata": {
        "id": "5Czkn87FuAFU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!detox -r /content/GFPGAN/inputs/upload/"
      ],
      "metadata": {
        "id": "XshuaCr7jxk5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Downsample images"
      ],
      "metadata": {
        "id": "UGGfgS_hs8Px"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import glob, os\n",
        "import os, sys\n",
        "from PIL import Image\n",
        "\n",
        "\n",
        "size = 256, 256\n",
        "# size = 128, 128\n",
        "\n",
        "os.chdir(\"/content/GFPGAN/inputs/upload\")\n",
        "for infile in glob.glob(\"*.png\"):\n",
        "    print(infile)\n",
        "\n",
        "    outfile = os.path.splitext(infile)[0] + \".jpg\"\n",
        "    if infile != outfile:\n",
        "        try:\n",
        "            im = Image.open(infile)\n",
        "            im.thumbnail(size, Image.ANTIALIAS)\n",
        "            im.save(outfile, \"JPEG\")\n",
        "        except IOError:\n",
        "            print(\"cannot create thumbnail for '%s'\" % infile)"
      ],
      "metadata": {
        "id": "y27KKsq1eBWW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!rm /content/GFPGAN/inputs/upload/*.png"
      ],
      "metadata": {
        "id": "LnR-yNp8gBKe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lGHc73Up70ZA"
      },
      "source": [
        "## 3. Inference"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/GFPGAN"
      ],
      "metadata": {
        "id": "Zh8ZO_6WnX5k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lmQVC3s97z4z"
      },
      "source": [
        "# Now we use the GFPGAN to restore the above low-quality images\n",
        "# We use [Real-ESRGAN](https://github.com/xinntao/Real-ESRGAN) for enhancing the background (non-face) regions\n",
        "# You can find the different models in https://github.com/TencentARC/GFPGAN#european_castle-model-zoo\n",
        "!rm -rf /content/GFPGAN/results/*\n",
        "!mkdir /content/GFPGAN/results\n",
        "!python /content/GFPGAN/inference_gfpgan.py -i /content/GFPGAN/inputs/upload -o /content/GFPGAN/results -v 1.3 -s 4 --bg_upsampler realesrgan\n",
        "\n",
        "# Usage: python inference_gfpgan.py -i inputs/whole_imgs -o results -v 1.3 -s 2 [options]...\n",
        "# \n",
        "#  -h                   show this help\n",
        "#  -i input             Input image or folder. Default: inputs/whole_imgs\n",
        "#  -o output            Output folder. Default: results\n",
        "#  -v version           GFPGAN model version. Option: 1 | 1.2 | 1.3. Default: 1.3\n",
        "#  -s upscale           The final upsampling scale of the image. Default: 2\n",
        "#  -bg_upsampler        background upsampler. Default: realesrgan\n",
        "#  -bg_tile             Tile size for background sampler, 0 for no tile during testing. Default: 400\n",
        "#  -suffix              Suffix of the restored faces\n",
        "#  -only_center_face    Only restore the center face\n",
        "#  -aligned             Input are aligned faces\n",
        "#  -ext                 Image extension. Options: auto | jpg | png, auto means using the same extension as inputs. Default: auto\n",
        "\n",
        "!ls /content/GFPGAN/results/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vkF8VAiF7-PY"
      },
      "source": [
        "## 4. Visualize -- deactivated for faster execution"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tIeL_NJO8A3B"
      },
      "source": [
        "# # We first visualize the cropped faces\n",
        "# # The left are the inputs images; the right are the results of GFPGAN\n",
        "\n",
        "# import cv2\n",
        "# import matplotlib.pyplot as plt\n",
        "# def display(img1, img2):\n",
        "#   fig = plt.figure(figsize=(25, 10))\n",
        "#   ax1 = fig.add_subplot(1, 2, 1) \n",
        "#   plt.title('Input image', fontsize=16)\n",
        "#   ax1.axis('off')\n",
        "#   ax2 = fig.add_subplot(1, 2, 2)\n",
        "#   plt.title('GFPGAN output', fontsize=16)\n",
        "#   ax2.axis('off')\n",
        "#   ax1.imshow(img1)\n",
        "#   ax2.imshow(img2)\n",
        "# def imread(img_path):\n",
        "#   img = cv2.imread(img_path)\n",
        "#   img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "#   return img\n",
        "\n",
        "# # display each image in the upload folder\n",
        "# import os\n",
        "# import glob\n",
        "\n",
        "# input_folder = 'results/cropped_faces'\n",
        "# result_folder = 'results/restored_faces'\n",
        "# input_list = sorted(glob.glob(os.path.join(input_folder, '*')))\n",
        "# output_list = sorted(glob.glob(os.path.join(result_folder, '*')))\n",
        "# for input_path, output_path in zip(input_list, output_list):\n",
        "#   img_input = imread(input_path)\n",
        "#   img_output = imread(output_path)\n",
        "#   display(img_input, img_output)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jn_2ylqP9qXY"
      },
      "source": [
        "# # We then visualize the whole image\n",
        "# # The left are the inputs images; the right are the results of GFPGAN\n",
        "\n",
        "# import cv2\n",
        "# import matplotlib.pyplot as plt\n",
        "# def display(img1, img2):\n",
        "#   fig = plt.figure(figsize=(25, 10))\n",
        "#   ax1 = fig.add_subplot(1, 2, 1) \n",
        "#   plt.title('Input image', fontsize=16)\n",
        "#   ax1.axis('off')\n",
        "#   ax2 = fig.add_subplot(1, 2, 2)\n",
        "#   plt.title('GFPGAN output', fontsize=16)\n",
        "#   ax2.axis('off')\n",
        "#   ax1.imshow(img1)\n",
        "#   ax2.imshow(img2)\n",
        "# def imread(img_path):\n",
        "#   img = cv2.imread(img_path)\n",
        "#   img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "#   return img\n",
        "\n",
        "# # display each image in the upload folder\n",
        "# import os\n",
        "# import glob\n",
        "\n",
        "# input_folder = 'inputs/upload'\n",
        "# result_folder = 'results/restored_imgs'\n",
        "# input_list = sorted(glob.glob(os.path.join(input_folder, '*')))\n",
        "# output_list = sorted(glob.glob(os.path.join(result_folder, '*')))\n",
        "# for input_path, output_path in zip(input_list, output_list):\n",
        "#   img_input = imread(input_path)\n",
        "#   img_output = imread(output_path)\n",
        "#   display(img_input, img_output)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HR7VEBEb8slX"
      },
      "source": [
        "## 5. Archive results"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## option faces only"
      ],
      "metadata": {
        "id": "Z_RqL17tdE8N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!rm /content/drive/MyDrive/AI/face_restore/output/*"
      ],
      "metadata": {
        "id": "K0RVFAWBdLEZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!cp /content/GFPGAN/results/restored_faces/* /content/drive/MyDrive/AI/face_restore/output"
      ],
      "metadata": {
        "id": "nAMhQ29Wc5n4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir /content/drive/MyDrive/AI/face_restore/$(date +%Y%m%d_%H%M%S) && mv /content/drive/MyDrive/AI/face_restore/output/*.png /content/drive/MyDrive/AI/face_restore/$(date +%Y%m%d_%H%M%S)"
      ],
      "metadata": {
        "id": "ECRTmZUmdECN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# option full image also"
      ],
      "metadata": {
        "id": "CMBs6RuSdHUf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!rm /content/drive/MyDrive/AI/face_restore/output/*"
      ],
      "metadata": {
        "id": "zCj17wNqdMhp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!cp /content/GFPGAN/results/restored_imgs/* /content/drive/MyDrive/AI/face_restore/output"
      ],
      "metadata": {
        "id": "XNjC5tHbqIOH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir /content/drive/MyDrive/AI/face_restore/$(date +%Y%m%d_%H%M%S) && mv /content/drive/MyDrive/AI/face_restore/output/*.jpg /content/drive/MyDrive/AI/face_restore/$(date +%Y%m%d_%H%M%S)"
      ],
      "metadata": {
        "id": "gin84Gf_qv47"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}