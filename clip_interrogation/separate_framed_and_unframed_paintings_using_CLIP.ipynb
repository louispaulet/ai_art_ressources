{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "33ECmjnGWR4z"
      ],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Lib install section"
      ],
      "metadata": {
        "id": "33ECmjnGWR4z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers"
      ],
      "metadata": {
        "id": "-bYSmwawxHNc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm.auto import tqdm\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import pandas as pd\n",
        "from transformers import CLIPProcessor, CLIPModel"
      ],
      "metadata": {
        "id": "npF76fWuNzzM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Define functions and prepare dataset\n",
        "\n"
      ],
      "metadata": {
        "id": "mDCevqADWV3R"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Order prompts based on an image"
      ],
      "metadata": {
        "id": "No4sC1zEdCYX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = CLIPModel.from_pretrained(\"openai/clip-vit-base-patch32\")\n",
        "processor = CLIPProcessor.from_pretrained(\"openai/clip-vit-base-patch32\")\n",
        "\n",
        "def order_prompts(model, processor, image, prompt_list):\n",
        "\n",
        "  inputs = processor(text=prompt_list, images=image, return_tensors=\"pt\", padding=True)\n",
        "  outputs = model(**inputs)\n",
        "  logits_per_image = outputs.logits_per_image  # this is the image-text similarity score\n",
        "  probs = logits_per_image.softmax(dim=1)  # we can take the softmax to get the label probabilities\n",
        "\n",
        "  df1 = pd.DataFrame(probs.detach().numpy()[0])\n",
        "  df2 = pd.DataFrame(prompt_list)\n",
        "\n",
        "  df = pd.concat([df1, df2], axis=1)\n",
        "  df.columns=['prob', 'prompt']\n",
        "\n",
        "  return df.sort_values('prob', ascending=False)"
      ],
      "metadata": {
        "id": "nlBd8MyvxC0v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Compute truth table cells"
      ],
      "metadata": {
        "id": "HIGHSs97YNFX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from glob import glob\n",
        "def count_framed_and_unframed_rations_from_path(file_path):\n",
        "\n",
        "  folder_filename_list = sorted(glob(file_path+\"/*\", recursive = True))\n",
        "\n",
        "  frammed_cpt = 0\n",
        "  unframmed_cpt = 0\n",
        "  for curr_file_path in folder_filename_list:\n",
        "    curr_filename = curr_file_path.split('/')[-1]\n",
        "    filename_prefix = curr_filename.split('_')[0]\n",
        "\n",
        "    if filename_prefix == \"framed\":\n",
        "      frammed_cpt = frammed_cpt +1\n",
        "    else:\n",
        "      unframmed_cpt = unframmed_cpt +1\n",
        "\n",
        "  \n",
        "  return frammed_cpt/len(folder_filename_list), unframmed_cpt/len(folder_filename_list)"
      ],
      "metadata": {
        "id": "MDhMDMpmISEO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Run the sorting"
      ],
      "metadata": {
        "id": "EUlPJ_ISYDku"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir -p \"/content/drive/MyDrive/AI/clip_interrogator/framed_unframed/output/framed\"\n",
        "!mkdir -p \"/content/drive/MyDrive/AI/clip_interrogator/framed_unframed/output/unframed\""
      ],
      "metadata": {
        "id": "ll2T3SVQ6dlJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# setup params\n",
        "frame_prompt_list = ['picture of a framed painting', 'picture of an unframed painting']\n",
        "input_path = \"/content/drive/MyDrive/AI/clip_interrogator/framed_unframed/input\"\n",
        "output_path = \"/content/drive/MyDrive/AI/clip_interrogator/framed_unframed/output\"\n",
        "\n",
        "# load file paths\n",
        "from glob import glob\n",
        "filename_list = sorted(glob(input_path+\"/*/*\", recursive = True))\n",
        "\n",
        "# run sorting\n",
        "for curr_filename in tqdm(filename_list):\n",
        "  image = Image.open(curr_filename)\n",
        "\n",
        "\n",
        "  df_out = order_prompts(model, processor, image, frame_prompt_list)\n",
        "  answer = df_out.iloc[0]['prompt']\n",
        "\n",
        "  filename = curr_filename.split('/')[-1]\n",
        "\n",
        "  if 'unframed' in answer:\n",
        "    target_file_path = output_path.replace('output', 'output/unframed/')\n",
        "    \n",
        "  else:\n",
        "    target_file_path = output_path.replace('output', 'output/framed/')\n",
        "  \n",
        "  target_file_path = target_file_path+filename\n",
        "  # print(target_file_path)\n",
        "  image.save(target_file_path)"
      ],
      "metadata": {
        "id": "U-XJWgIn586E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Compute Truth Table"
      ],
      "metadata": {
        "id": "E6mhgU6yYHjB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "framed_output = \"/content/drive/MyDrive/AI/clip_interrogator/framed_unframed/output/framed\"\n",
        "unframed_output = \"/content/drive/MyDrive/AI/clip_interrogator/framed_unframed/output/unframed\""
      ],
      "metadata": {
        "id": "6NbYHIVKBNQL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "count_framed_and_unframed_rations_from_path(framed_output)"
      ],
      "metadata": {
        "id": "5mm-kUKoIUvS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "count_framed_and_unframed_rations_from_path(unframed_output)"
      ],
      "metadata": {
        "id": "u9gLO-BlJGfj"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}